# backend/app/repositories/ubicacion_repository.py
from __future__ import annotations

from typing import Any, Dict, List, Optional
import psycopg
from psycopg.rows import dict_row
from psycopg import conninfo

from app.config.settings import Settings


class UbicacionRepository:
    """
    Repositorio que maneja su propia conexión psycopg (igual que UserService).
    Soporta __init__(db=None) para compatibilidad con llamadas antiguas.
    """

    def __init__(self, db: Any = None) -> None:  # db ignorado (compat)
        # DSN robusto (evita problemas de espacios/símbolos en credenciales)
        self.dsn = conninfo.make_conninfo(
            host=Settings.DB_HOST,
            port=str(Settings.DB_PORT),
            dbname=Settings.DB_NAME,
            user=Settings.DB_USER,
            password=Settings.DB_PASSWORD,
        )

    # --- esquema ---
    def ensure_schema(self) -> None:
        """
        Crea la tabla e índices si no existen. Evita el choque con sequences
        usando IDENTITY en lugar de BIGSERIAL (que fue la causa del error
        'pg_class_relname_nsp_index' por 'ubicaciones_id_seq' duplicada).
        """
        ddl_table = """
        CREATE TABLE IF NOT EXISTS public.ubicaciones (
          id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
          nombre TEXT NOT NULL,
          lat DOUBLE PRECISION NOT NULL,
          lng DOUBLE PRECISION NOT NULL,
          activo BOOLEAN NOT NULL DEFAULT TRUE,
          created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
          updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
        );
        """
        ddl_idx = [
            "CREATE INDEX IF NOT EXISTS idx_ubicaciones_activo ON public.ubicaciones(activo)",
            "CREATE INDEX IF NOT EXISTS idx_ubicaciones_lat ON public.ubicaciones(lat)",
            "CREATE INDEX IF NOT EXISTS idx_ubicaciones_lng ON public.ubicaciones(lng)",
            "CREATE INDEX IF NOT EXISTS idx_ubicaciones_updated_at ON public.ubicaciones(updated_at)",
            "CREATE INDEX IF NOT EXISTS idx_ubicaciones_lng_lat ON public.ubicaciones(lng, lat)",
        ]

        with psycopg.connect(self.dsn) as conn:
            with conn.cursor() as cur:
                cur.execute(ddl_table)
                for ddl in ddl_idx:
                    cur.execute(ddl)
            conn.commit()

    # --- escrituras ---
    def crear(self, data: Dict[str, Any]) -> Dict[str, Any]:
        sql = """
        INSERT INTO public.ubicaciones (nombre, lat, lng, activo)
        VALUES (%s, %s, %s, COALESCE(%s, TRUE))
        RETURNING id, nombre, lat, lng, activo, created_at, updated_at
        """
        nombre = (data.get("nombre") or "").strip()
        lat = float(data["lat"])
        lng = float(data["lng"])
        activo = data.get("activo", True)

        with psycopg.connect(self.dsn) as conn, conn.cursor(row_factory=dict_row) as cur:
            cur.execute(sql, (nombre, lat, lng, activo))
            row = cur.fetchone()
            conn.commit()
            return dict(row)

    def actualizar(
        self,
        ubic_id: int,
        *,
        nombre: Optional[str] = None,
        lat: Optional[float] = None,
        lng: Optional[float] = None,
        activo: Optional[bool] = None,
    ) -> Optional[Dict[str, Any]]:
        sets, params = [], []
        if nombre is not None:
            sets.append("nombre=%s")
            params.append(nombre.strip())
        if lat is not None:
            sets.append("lat=%s")
            params.append(float(lat))
        if lng is not None:
            sets.append("lng=%s")
            params.append(float(lng))
        if activo is not None:
            sets.append("activo=%s")
            params.append(bool(activo))

        if not sets:
            return self.obtener(ubic_id)

        params.append(ubic_id)
        sql = f"""
        UPDATE public.ubicaciones
        SET {', '.join(sets)}, updated_at=NOW()
        WHERE id=%s
        RETURNING id, nombre, lat, lng, activo, created_at, updated_at
        """
        with psycopg.connect(self.dsn) as conn, conn.cursor(row_factory=dict_row) as cur:
            cur.execute(sql, tuple(params))
            row = cur.fetchone()
            conn.commit()
            return dict(row) if row else None

    def eliminar(self, ubic_id: int) -> bool:
        sql = "DELETE FROM public.ubicaciones WHERE id=%s"
        with psycopg.connect(self.dsn) as conn, conn.cursor() as cur:
            cur.execute(sql, (ubic_id,))
            deleted = cur.rowcount
            conn.commit()
            return deleted > 0

    # --- lecturas ---
    def obtener(self, ubic_id: int) -> Optional[Dict[str, Any]]:
        sql = """
        SELECT id, nombre, lat, lng, activo, created_at, updated_at
        FROM public.ubicaciones WHERE id=%s
        """
        with psycopg.connect(self.dsn) as conn, conn.cursor(row_factory=dict_row) as cur:
            cur.execute(sql, (ubic_id,))
            row = cur.fetchone()
            return dict(row) if row else None

    def listar_paginado(self, page: int = 1, size: int = 100) -> Dict[str, Any]:
        page = max(page, 1)
        size = max(min(size, 500), 1)
        offset = (page - 1) * size

        count_sql = "SELECT COUNT(*) FROM public.ubicaciones"
        list_sql = """
        SELECT id, nombre, lat, lng, activo, created_at, updated_at
        FROM public.ubicaciones
        ORDER BY id DESC
        LIMIT %s OFFSET %s
        """
        with psycopg.connect(self.dsn) as conn:
            with conn.cursor() as cur:
                cur.execute(count_sql)
                total = int(cur.fetchone()[0])

            with conn.cursor(row_factory=dict_row) as cur:
                cur.execute(list_sql, (size, offset))
                rows = [dict(r) for r in cur.fetchall()]

        return {"items": rows, "page": page, "size": size, "total": total}

    def listar_bbox(
        self,
        min_lng: float,
        min_lat: float,
        max_lng: float,
        max_lat: float,
    ) -> List[Dict[str, Any]]:
        sql = """
        SELECT id, nombre, lat, lng, activo, created_at, updated_at
        FROM public.ubicaciones
        WHERE lng BETWEEN %s AND %s
          AND lat BETWEEN %s AND %s
        ORDER BY updated_at DESC
        """
        with psycopg.connect(self.dsn) as conn, conn.cursor(row_factory=dict_row) as cur:
            cur.execute(sql, (min_lng, max_lng, min_lat, max_lat))
            return [dict(r) for r in cur.fetchall()]

    # --- agregados para dashboard ---
    def contar_total(self) -> int:
        with psycopg.connect(self.dsn) as conn, conn.cursor() as cur:
            cur.execute("SELECT COUNT(*) FROM public.ubicaciones")
            return int(cur.fetchone()[0])

    def contar_activas(self) -> int:
        with psycopg.connect(self.dsn) as conn, conn.cursor() as cur:
            cur.execute("SELECT COUNT(*) FROM public.ubicaciones WHERE activo=TRUE")
            return int(cur.fetchone()[0])

    def ultima_actualizacion_iso(self) -> Optional[str]:
        with psycopg.connect(self.dsn) as conn, conn.cursor() as cur:
            cur.execute("SELECT MAX(updated_at) FROM public.ubicaciones")
            ts = cur.fetchone()[0]
            return ts.isoformat() if ts else None

    def recientes(self, limit: int = 20) -> List[Dict[str, Any]]:
        sql = """
        SELECT id, nombre, lat, lng, activo, created_at, updated_at
        FROM public.ubicaciones
        ORDER BY updated_at DESC
        LIMIT %s
        """
        with psycopg.connect(self.dsn) as conn, conn.cursor(row_factory=dict_row) as cur:
            cur.execute(sql, (limit,))
            return [dict(r) for r in cur.fetchall()]
